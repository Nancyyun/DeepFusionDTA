{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import h5py\n",
    "import pickle\n",
    "import json\n",
    "from tensorflow.keras.models import Model\n",
    "from collections import OrderedDict\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import random as rn\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"  #指定要使用的GPU序号\n",
    "\n",
    "np.random.seed(1)\n",
    "rn.seed(1)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "session_conf.gpu_options.allow_growth=True   \t  #不全部占满显存, 动态增长\n",
    "from tensorflow.keras import backend as K\n",
    "tf.set_random_seed(0)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cindex_score(y_true, y_pred):\n",
    "\n",
    "    g = tf.subtract(tf.expand_dims(y_pred, -1), y_pred)\n",
    "    g = tf.cast(g == 0.0, tf.float32) * 0.5 + tf.cast(g > 0.0, tf.float32)\n",
    "\n",
    "    f = tf.subtract(tf.expand_dims(y_true, -1), y_true) > 0.0\n",
    "    f = tf.matrix_band_part(tf.cast(f, tf.float32), -1, 0)\n",
    "\n",
    "    g = tf.reduce_sum(tf.multiply(g, f))\n",
    "    f = tf.reduce_sum(f)\n",
    "\n",
    "    return tf.where(tf.equal(g, 0), 0.0, g/f) #select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_interaction_pairs(XD, XD_STRU, XT, XT_STRU, Y, rows, cols):\n",
    "    drugs = []\n",
    "    drugs_stru = []\n",
    "    targets = []\n",
    "    targets_stru = []\n",
    "    affinity=[] \n",
    "        \n",
    "    for pair_ind in range(len(rows)):\n",
    "        drug = XD[rows[pair_ind]]\n",
    "        drugs.append(drug)\n",
    "\n",
    "        drug_stru = XD_STRU[rows[pair_ind]]\n",
    "        drugs_stru.append(drug_stru)\n",
    "\n",
    "        target=XT[cols[pair_ind]]\n",
    "        targets.append(target)\n",
    "\n",
    "        target_stru = XT_STRU[cols[pair_ind]]\n",
    "        targets_stru.append(target_stru)\n",
    "\n",
    "        affinity.append(Y[rows[pair_ind],cols[pair_ind]])\n",
    "\n",
    "    drug_data = np.stack(drugs)\n",
    "    drug_stru_data = np.stack(drugs_stru)\n",
    "    target_data = np.stack(targets)\n",
    "    target_stru_data = np.stack(targets_stru)\n",
    "\n",
    "    return drug_data, drug_stru_data, target_data, target_stru_data, affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_h5File_test(XD, XD_STRU, XT, XT_STRU, Y):\n",
    "    label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)\n",
    "    model = keras.models.load_model(f'3_1_model.h5', custom_objects={'cindex_score': cindex_score})\n",
    "    new_model = Model(inputs=model.input,outputs=model.get_layer('DenseFeature').output)\n",
    "\n",
    "    \n",
    "    test_sets = json.load(open(\"data/davis/folds/test_fold_setting1.txt\"))\n",
    "    train_sets = json.load(open(\"train_fold_setting_full.txt\"))\n",
    "    \n",
    "    terows = label_row_inds[test_sets]\n",
    "    tecols = label_col_inds[test_sets]\n",
    "    test_drugs, test_drugs_stru, test_prots, test_prots_stru, test_Y = prepare_interaction_pairs(XD, XD_STRU, XT, XT_STRU, Y, terows, tecols)\n",
    "    \n",
    "    trrows = label_row_inds[train_sets]\n",
    "    trcols = label_col_inds[train_sets]\n",
    "    train_drugs, train_drugs_stru, train_prots, train_prots_stru, train_Y = prepare_interaction_pairs(XD, XD_STRU, XT, XT_STRU, Y, trrows, trcols)\n",
    "    \n",
    "    #f = h5py.File(\"DenseFeature.h5\",\"w\")\n",
    "    #NNFeature = new_model.predict([np.array(train_drugs),np.array(train_drugs_stru),np.array(train_prots),np.array(train_prots_stru)])\n",
    "    #print(len(train_Y))\n",
    "    #TeNNFeature = new_model.predict([np.array(test_drugs), np.array(test_drugs_stru), np.array(test_prots),np.array(test_prots_stru)])\n",
    "    #print(NNFeature.shape, TeNNFeature.shape)\n",
    "    #print(len(test_Y))\n",
    "    #d1 = f.create_dataset(\"train_feature\",(NNFeature.shape[0], 512),'f', np.array(NNFeature))\n",
    "    #d2 = f.create_dataset(\"test_feature\",(TeNNFeature.shape[0], 512),'f', np.array(TeNNFeature))\n",
    "    #f.close()\n",
    "    with open('test_Y.txt','w') as file_object:\n",
    "        json.dump(test_Y,file_object)\n",
    "    with open('train_Y.txt','w') as file_object:\n",
    "        json.dump(train_Y,file_object)\n",
    "    return 'SAVE OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARPROTSET = { \"A\": 1, \"C\": 2, \"B\": 3, \"E\": 4, \"D\": 5, \"G\": 6, \n",
    "\t\t\t\t\"F\": 7, \"I\": 8, \"H\": 9, \"K\": 10, \"M\": 11, \"L\": 12, \n",
    "\t\t\t\t\"O\": 13, \"N\": 14, \"Q\": 15, \"P\": 16, \"S\": 17, \"R\": 18, \n",
    "\t\t\t\t\"U\": 19, \"T\": 20, \"W\": 21, \n",
    "\t\t\t\t\"V\": 22, \"Y\": 23, \"X\": 24, \n",
    "\t\t\t\t\"Z\": 25 }\n",
    "\n",
    "CHARPROTLEN = 25\n",
    "\n",
    "CHARPROTSTRUSET = {\"C\": 1,\"H\": 2,\"E\": 3}\n",
    "\n",
    "CHARPROTSTRULEN =3\n",
    "\n",
    "CHARCANSMISET = { \"#\": 1, \"%\": 2, \")\": 3, \"(\": 4, \"+\": 5, \"-\": 6, \n",
    "\t\t\t \".\": 7, \"1\": 8, \"0\": 9, \"3\": 10, \"2\": 11, \"5\": 12, \n",
    "\t\t\t \"4\": 13, \"7\": 14, \"6\": 15, \"9\": 16, \"8\": 17, \"=\": 18, \n",
    "\t\t\t \"A\": 19, \"C\": 20, \"B\": 21, \"E\": 22, \"D\": 23, \"G\": 24,\n",
    "\t\t\t \"F\": 25, \"I\": 26, \"H\": 27, \"K\": 28, \"M\": 29, \"L\": 30, \n",
    "\t\t\t \"O\": 31, \"N\": 32, \"P\": 33, \"S\": 34, \"R\": 35, \"U\": 36, \n",
    "\t\t\t \"T\": 37, \"W\": 38, \"V\": 39, \"Y\": 40, \"[\": 41, \"Z\": 42, \n",
    "\t\t\t \"]\": 43, \"_\": 44, \"a\": 45, \"c\": 46, \"b\": 47, \"e\": 48, \n",
    "\t\t\t \"d\": 49, \"g\": 50, \"f\": 51, \"i\": 52, \"h\": 53, \"m\": 54, \n",
    "\t\t\t \"l\": 55, \"o\": 56, \"n\": 57, \"s\": 58, \"r\": 59, \"u\": 60,\n",
    "\t\t\t \"t\": 61, \"y\": 62}\n",
    "\n",
    "CHARCANSMILEN = 62\n",
    "\n",
    "CHARISOSMISET = {\"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2, \n",
    "\t\t\t\t\"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6, \n",
    "\t\t\t\t\"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43, \n",
    "\t\t\t\t\"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13, \n",
    "\t\t\t\t\"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51, \n",
    "\t\t\t\t\"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56, \n",
    "\t\t\t\t\"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60, \n",
    "\t\t\t\t\"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64}\n",
    "\n",
    "CHARISOSMILEN = 64\n",
    "\n",
    "\n",
    "## ######################## ##\n",
    "#\n",
    "#  Encoding Helpers\n",
    "#\n",
    "## ######################## ## \n",
    "\n",
    "#  Y = -(np.log10(Y/(math.pow(math.e,9))))\n",
    "\n",
    "def one_hot_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "\tX = np.zeros((MAX_SMI_LEN, len(smi_ch_ind))) #+1\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]):\n",
    "\t\tX[i, (smi_ch_ind[ch]-1)] = 1 \n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def one_hot_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind))) \n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i, (smi_ch_ind[ch])-1] = 1\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def one_hot_structure(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "    X = np.zeros((MAX_SEQ_LEN, len(smi_ch_ind)))\n",
    "    for i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "        X[i, (smi_ch_ind[ch])-1] = 1\n",
    "\n",
    "    return X \n",
    "\n",
    "def label_smiles(line, MAX_SMI_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SMI_LEN)\n",
    "\tfor i, ch in enumerate(line[:MAX_SMI_LEN]): #\tx, smi_ch_ind, y\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def label_sequence(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "\tX = np.zeros(MAX_SEQ_LEN)\n",
    "\n",
    "\tfor i, ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "\t\tX[i] = smi_ch_ind[ch]\n",
    "\n",
    "\treturn X #.tolist()\n",
    "\n",
    "def label_structure(line, MAX_SEQ_LEN, smi_ch_ind):\n",
    "    X = np.zeros(MAX_SEQ_LEN)\n",
    "    for i,ch in enumerate(line[:MAX_SEQ_LEN]):\n",
    "        X[i] = smi_ch_ind[ch]\n",
    "\n",
    "    return X\n",
    "\n",
    "def pure_ligands_structure(line, MAX_SEQ_LEN):\n",
    "    X = np.zeros(MAX_SEQ_LEN)\n",
    "    line = line.split(\",\")\n",
    "    for i, ch in enumerate(line[:MAX_SEQ_LEN]): \n",
    "        X[i] = int(ch)\n",
    "    return X\n",
    "\n",
    "\n",
    "## ######################## ##\n",
    "#\n",
    "#  DATASET Class\n",
    "#\n",
    "## ######################## ## \n",
    "# works for large dataset\n",
    "\n",
    "\n",
    "\n",
    "def parse_data(is_log=True, with_label=True):\n",
    "    fpath = 'data/davis/'\n",
    "    print(\"Read %s start\" % fpath)\n",
    "    SMILEN = 85\n",
    "    SEQLEN = 1200\n",
    "    SMISTRULEN = 60\n",
    "    charsmiset = CHARISOSMISET\n",
    "    charseqset = CHARPROTSET\n",
    "    charseqstruset = CHARPROTSTRUSET\n",
    "    charseqstruset_size = CHARPROTSTRULEN\n",
    "\n",
    "    ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "    proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "    proteins_structure = json.load(open(fpath+\"protein_structure.txt\"), object_pairs_hook=OrderedDict)\n",
    "    ligands_structure = json.load(open(fpath+\"morgan_fingerprint.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "    Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw\n",
    "    if is_log:\n",
    "        Y = -(np.log10(Y/(math.pow(10,9))))\n",
    "\n",
    "    XD = []\n",
    "    XT = []\n",
    "    XT_STRU = []\n",
    "    XD_STRU = []\n",
    "\n",
    "    if with_label:\n",
    "        for d in ligands.keys():\n",
    "            XD.append(label_smiles(ligands[d], SMILEN, charsmiset))\n",
    "            XD_STRU.append(pure_ligands_structure(ligands_structure[d], SMISTRULEN))\n",
    "\n",
    "        for t in proteins.keys():\n",
    "            XT.append(label_sequence(proteins[t], SEQLEN, charseqset))\n",
    "            XT_STRU.append(label_structure(proteins_structure[t], SEQLEN, charseqstruset))\n",
    "    else:\n",
    "        for d in ligands.keys():\n",
    "            XD.append(one_hot_smiles(ligands[d], SMILEN, charsmiset))\n",
    "            XD_STRU.append(pure_ligands_structure(ligands_structure[d], SMISTRULEN))\n",
    "\n",
    "        for t in proteins.keys():\n",
    "            XT.append(one_hot_sequence(proteins[t], SEQLEN, charseqset))\n",
    "            XT_STRU.append(one_hot_structure(proteins_structure[t], SEQLEN, charseqstruset))\n",
    "  \n",
    "    return XD, XD_STRU, XT, XT_STRU, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data/davis/ start\n"
     ]
    }
   ],
   "source": [
    "XD, XD_STRU, XT, XT_STRU, Y = parse_data(with_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/puyuqian/anaconda3/envs/tf1.15/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/puyuqian/anaconda3/envs/tf1.15/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/puyuqian/anaconda3/envs/tf1.15/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/puyuqian/anaconda3/envs/tf1.15/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/puyuqian/anaconda3/envs/tf1.15/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/puyuqian/anaconda3/envs/tf1.15/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-2-630fb1f8057b>:12: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SAVE OK'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_h5File_test(XD, XD_STRU, XT, XT_STRU, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
